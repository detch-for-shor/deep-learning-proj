{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import  Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luciahrovatin/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import imagesize\n",
    "import zipfile \n",
    "import statistics \n",
    "import math\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import Tensor\n",
    "from torchvision import models\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import RMSprop, Adagrad\n",
    "from overrides import overrides, final\n",
    "from abc import abstractmethod\n",
    "#from google.colab import drive\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"backpack\", \"bookcase\", \"car jack\", \"comb\", \"crown\", \"file cabinet\", \"flat iron\", \"game controller\", \"glasses\",\n",
    "           \"helicopter\", \"ice skates\", \"letter tray\", \"monitor\", \"mug\", \"network switch\", \"over-ear headphones\", \"pen\",\n",
    "           \"purse\", \"stand mixer\", \"stroller\"]\n",
    "\n",
    "domains = [\"product_images\", \"real_life\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_transformation(resize_dim = 256, crop_dim = 224, grayscale = True, crop_center = True):\n",
    "    \n",
    "    transform_lst = []\n",
    "    transform_lst.append(T.Resize((resize_dim)))                                                          \n",
    "    \n",
    "    if grayscale:\n",
    "        transform_lst.append(T.Grayscale(num_output_channels=3))                        \n",
    "    \n",
    "    if crop_center:\n",
    "        transform_lst.append(T.CenterCrop((crop_dim)))\n",
    "    else:\n",
    "        transform_lst.append(T.RandomCrop((crop_dim)))\n",
    "    \n",
    "    transform_lst.append(T.RandomHorizontalFlip(p=0.5))                                  \n",
    "    transform_lst.append(T.ToTensor())                                             \n",
    "        \n",
    "    return T.Compose(transform_lst)  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalization(dataset):\n",
    "    ds_length = len(dataset)\n",
    "    for i in tqdm(range(ds_length)):\n",
    "        r_mean, g_mean, b_mean = torch.mean(dataset[i][0], dim = [1,2])\n",
    "        r_std, g_std, b_std = torch.std(dataset[i][0], dim = [1,2])\n",
    "        T.functional.normalize(\n",
    "            tensor = dataset[i][0], \n",
    "            mean = [r_mean, g_mean, b_mean],\n",
    "            std = [r_std, g_std, b_std],\n",
    "            inplace=True\n",
    "            )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [01:38<00:00, 20.25it/s]\n",
      "100%|██████████| 2000/2000 [02:51<00:00, 11.67it/s]\n"
     ]
    }
   ],
   "source": [
    "source = \"product_images\"\n",
    "target = \"real_life\"\n",
    "resize_dim = 256\n",
    "crop_dim = 224\n",
    "grayscale = False\n",
    "crop_center = True \n",
    "\n",
    "\n",
    "source_ds = torchvision.datasets.ImageFolder(\n",
    "    root = f\"data/Adaptiope/{source}\",\n",
    "    transform = data_transformation(resize_dim, crop_dim, grayscale, crop_center)\n",
    "    )\n",
    "\n",
    "target_ds = torchvision.datasets.ImageFolder(\n",
    "    root = f\"data/Adaptiope/{target}\",\n",
    "    transform = data_transformation(resize_dim, crop_dim, grayscale, crop_center)\n",
    "    ) \n",
    "\n",
    "if not grayscale:\n",
    "    normalization(source_ds)\n",
    "    normalization(target_ds)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(dataset, test_split=0.2, batch_size=32):\n",
    "    \n",
    "    train_indices, val_indices = train_test_split(\n",
    "        list(range(len(dataset.targets))),\n",
    "        test_size = test_split,\n",
    "        stratify = dataset.targets, \n",
    "        random_state = 42\n",
    "        )\n",
    "    \n",
    "    train_dataset = Subset(dataset, train_indices)\n",
    "    val_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "    train_data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_data_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_data_loader, val_data_loader\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "test_split = 0.2\n",
    "\n",
    "source_train_loader, source_val_loader = get_data(source_ds, test_split, batch_size)\n",
    "target_train_loader, target_val_loader = get_data(target_ds, test_split, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Loss(torch.nn.Module):\n",
    "    \n",
    "    _THRESHOLD = 1e-20\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(_Loss, self).__init__()\n",
    "        \n",
    "    def forward(self, input: Tensor):\n",
    "        prob = self.to_softmax(input)\n",
    "        return self.loss(prob)\n",
    "        \n",
    "    @final\n",
    "    def add_threshold(self, prob: Tensor):\n",
    "        '''\n",
    "        Check whether the probability distribution after the softmax \n",
    "        is equal to 0 in any cell. If this holds, a standard threshold\n",
    "        is added in order to avoid log(0) case. \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        prob: Tensor\n",
    "            output tensor of the softmax operation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            updated tensor (in case the condition above holds)\n",
    "        '''\n",
    "        zeros = (prob == 0)\n",
    "        if torch.any(zeros):\n",
    "            thre_tensor = torch.zeros(zeros.shape)\n",
    "            thre_tensor[zeros] = self._THRESHOLD\n",
    "            prob = prob + thre_tensor\n",
    "        return prob\n",
    "    \n",
    "    def to_softmax(self, features: Tensor):\n",
    "        '''\n",
    "        Apply the softmax operation on the features tensor, \n",
    "        being the output of a feature extractor. \n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        features: Tensor\n",
    "            input tensor of the softmax operation\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Tensor\n",
    "            probability distribution with (possible) threshold\n",
    "        '''\n",
    "        prob = F.softmax(features, dim=1)\n",
    "        return self.add_threshold(prob)\n",
    "    \n",
    "    @abstractmethod\n",
    "    def loss(self, prob: Tensor):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EntropyMinimizationLoss(_Loss):\n",
    "    \n",
    "    def __init__(self, n_classes: int):\n",
    "        super(EntropyMinimizationLoss, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "    \n",
    "    @overrides\n",
    "    def loss(self, prob: Tensor):\n",
    "        prob_source = prob[:, :self.n_classes]\n",
    "        prob_target = prob[:, self.n_classes:]\n",
    "        prob_sum = prob_source + prob_target\n",
    "        return -(prob_sum.log().mul(prob_sum).sum(dim=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitLoss(_Loss):\n",
    "    \n",
    "    def __init__(self, n_classes: int, source: bool, split_first: bool):\n",
    "        super(SplitLoss, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self._is_source = source\n",
    "        self._split_first = split_first\n",
    "    \n",
    "    @overrides\n",
    "    def to_softmax(self, features: Tensor):\n",
    "        if self._split_first:\n",
    "            prob = self.split_vector(features)\n",
    "            prob = F.softmax(prob, dim=1)\n",
    "        else:\n",
    "            prob = F.softmax(features, dim=1)\n",
    "            prob = self.split_vector(prob)\n",
    "        return self.add_threshold(prob)\n",
    "    \n",
    "    @final\n",
    "    def split_vector(self, prob: Tensor):\n",
    "        return prob[:,:self.n_classes] if self._is_source else prob[:,self.n_classes:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SplitCrossEntropyLoss(SplitLoss):\n",
    "    \n",
    "    def _get_y_labels(self):\n",
    "        return self._y_labels\n",
    "    def _set_y_labels(self, y_labels: Variable):\n",
    "        if not all(y < self.n_classes for y in y_labels):\n",
    "            raise ValueError('Expected all y labels < n_classes')\n",
    "        self._y_labels = y_labels\n",
    "    y_labels = property(fget=_get_y_labels, fset=_set_y_labels)\n",
    "    \n",
    "    def __init__(self, n_classes: int, source: bool, split_first: bool):\n",
    "        super(SplitCrossEntropyLoss, self).__init__(n_classes, source, split_first)\n",
    "        self.cross_entropy_loss = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    @overrides\n",
    "    def loss(self, prob: Tensor):\n",
    "        '''Computes cross-entropy loss w.r.t. ground-truth (y label)'''\n",
    "        return self.cross_entropy_loss(prob, self.y_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DomainDiscriminationLoss(SplitLoss):\n",
    "    \n",
    "    def __init__(self, n_classes: int, source: bool):\n",
    "        super(DomainDiscriminationLoss, self).__init__(n_classes, source, False)\n",
    "        \n",
    "    @overrides\n",
    "    def loss(self, prob: Tensor):\n",
    "        return -(prob.sum(dim=1).log().mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingObjectives:\n",
    "    \n",
    "    @staticmethod\n",
    "    def domain_discrimination_loss(src_dom_discrim_loss, tgt_dom_discrim_loss):\n",
    "        return src_dom_discrim_loss + tgt_dom_discrim_loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def category_confusion_loss(src_cat_conf_loss, tgt_cat_conf_loss):\n",
    "        return 0.5 * (src_cat_conf_loss + tgt_cat_conf_loss)\n",
    "    \n",
    "    @staticmethod\n",
    "    def domain_confusion_loss(src_dom_conf_loss, tgt_dom_conf_loss):\n",
    "        return 0.5 * (src_dom_conf_loss + tgt_dom_conf_loss)\n",
    "    \n",
    "    @staticmethod\n",
    "    def overall_classifier_loss(src_task_class_loss, tgt_task_class_loss, domain_discrim_loss):\n",
    "        return src_task_class_loss + tgt_task_class_loss + domain_discrim_loss\n",
    "    \n",
    "    @staticmethod\n",
    "    def overall_generator_loss(cat_conf_loss, dom_conf_loss, tgt_entropy_loss, curr_epoch, tot_epochs):\n",
    "        lambda_trade_off = 2 / (1 + math.exp(-1 * 10 * curr_epoch / tot_epochs)) - 1\n",
    "        return cat_conf_loss + lambda_trade_off * (dom_conf_loss + tgt_entropy_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor:\n",
    "    \n",
    "    def __init__(self, n_classes: int, n_params_trained = None, model='resnet50', optimizer='rmsprop', lr=0.01, weight_decay=0):\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            n_classes (int): number of classes present in the dataset\n",
    "            n_params_trained (_type_, optional): Number of parameters (i.e., layers to be trained). Defaults to None.\n",
    "            model (str, optional): Pretrained model to import as feature extractor. Defaults to 'resnet18'.\n",
    "            optimizer (str, optional): Optimizer for the model. Defaults to 'rmsprop'.\n",
    "            lr (float, optional): Initial learning rate. Defaults to 0.01.\n",
    "            weight_decay (int, optional): Initial weight decay. Defaults to 0.\n",
    "        \"\"\"\n",
    "\n",
    "        # Upload pretrained model \n",
    "        if model.lower() == 'resnet18': \n",
    "            self.model = models.resnet18(pretrained=True)\n",
    "        elif model.lower() == 'resnet50': \n",
    "            self.model = models.resnet50(pretrained=True)\n",
    "        else:\n",
    "            raise ValueError('Unknown model')\n",
    "        \n",
    "        # Modify last fully-connected layer\n",
    "        self.model.fc = torch.nn.Linear(\n",
    "            in_features = self.model.fc.in_features, \n",
    "            out_features = n_classes * 2\n",
    "        )\n",
    "        \n",
    "        n_params = len(list(self.model.parameters()))\n",
    "        if n_params_trained is None:\n",
    "            n_params_trained = n_params\n",
    "            \n",
    "        count = 0 \n",
    "        first_param_trained = n_params - n_params_trained\n",
    "        for param in self.model.parameters():\n",
    "            #n_params_frozen = n_params - count - 1\n",
    "            #param.requires_grad = (n_params_frozen < n_params_trained)\n",
    "            param.requires_grad = (count >= first_param_trained)\n",
    "            count = count + 1 \n",
    "            \n",
    "        params_to_train = filter(lambda p: p.requires_grad, self.model.parameters())\n",
    "        \n",
    "        # Initialize optimizer\n",
    "        if optimizer.lower() == 'rmsprop':\n",
    "            self.optim = torch.optim.RMSprop(\n",
    "                params = params_to_train,\n",
    "                lr = lr,\n",
    "                weight_decay = weight_decay\n",
    "            )\n",
    "        elif optimizer.lower() == 'adadelta':\n",
    "            self.optim = torch.optim.Adadelta(\n",
    "                params = params_to_train,\n",
    "                lr = lr,\n",
    "                weight_decay = weight_decay\n",
    "            )\n",
    "        elif optimizer.lower() == 'sgd':\n",
    "            self.optim = torch.optim.SGD(\n",
    "                params = params_to_train,\n",
    "                lr = lr,\n",
    "                weight_decay = weight_decay,\n",
    "                nesterov = True\n",
    "            )\n",
    "        else:\n",
    "            raise ValueError('Unknown optimizer')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    \n",
    "    def __init__(self, model: FeatureExtractor, n_classes: int, epochs: int):\n",
    "        \"\"\"Initialize the SymsNet model\n",
    "        Args:\n",
    "            model (FeatureExtractor): _description_\n",
    "            n_classes (int): _description_\n",
    "            epochs (int): _description_\n",
    "        \"\"\"\n",
    "        \n",
    "       \n",
    "        self.curr_epoch = 0\n",
    "        self.tot_epochs = epochs\n",
    "        self.n_classes = n_classes\n",
    "        self.model = model \n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.model = self.model.cuda()\n",
    "            # Task classifier losses\n",
    "            self.src_task_class_loss = SplitCrossEntropyLoss(n_classes=n_classes, source=True, split_first=True).cuda()\n",
    "            self.tgt_task_class_loss = SplitCrossEntropyLoss(n_classes=n_classes, source=False, split_first=True).cuda()\n",
    "            # Domain discrimination losses\n",
    "            self.src_dom_discrim_loss = DomainDiscriminationLoss(n_classes=n_classes, source=True).cuda()\n",
    "            self.tgt_dom_discrim_loss = DomainDiscriminationLoss(n_classes=n_classes, source=False).cuda()\n",
    "            # Category-level confusion losses\n",
    "            self.src_cat_conf_loss = SplitCrossEntropyLoss(n_classes=n_classes, source=True, split_first=False).cuda()\n",
    "            self.tgt_cat_conf_loss = SplitCrossEntropyLoss(n_classes=n_classes, source=False, split_first=False).cuda()\n",
    "            # Domain-level confusion losses\n",
    "            self.src_dom_conf_loss = DomainDiscriminationLoss(n_classes=n_classes, source=True).cuda()\n",
    "            self.tgt_dom_conf_loss = DomainDiscriminationLoss(n_classes=n_classes, source=False).cuda()\n",
    "            # Entropy minimization loss\n",
    "            self.tgt_entropy_loss = EntropyMinimizationLoss(n_classes=n_classes).cuda()    \n",
    "        \n",
    "        else: \n",
    "            self.src_task_class_loss = SplitCrossEntropyLoss(n_classes=n_classes, source=True, split_first=True)\n",
    "            self.tgt_task_class_loss = SplitCrossEntropyLoss(n_classes=n_classes, source=False, split_first=True)\n",
    "            # Domain discrimination losses\n",
    "            self.src_dom_discrim_loss = DomainDiscriminationLoss(n_classes=n_classes, source=True)\n",
    "            self.tgt_dom_discrim_loss = DomainDiscriminationLoss(n_classes=n_classes, source=False)\n",
    "            # Category-level confusion losses\n",
    "            self.src_cat_conf_loss = SplitCrossEntropyLoss(n_classes=n_classes, source=True, split_first=False)\n",
    "            self.tgt_cat_conf_loss = SplitCrossEntropyLoss(n_classes=n_classes, source=False, split_first=False)\n",
    "            # Domain-level confusion losses\n",
    "            self.src_dom_conf_loss = DomainDiscriminationLoss(n_classes=n_classes, source=True)\n",
    "            self.tgt_dom_conf_loss = DomainDiscriminationLoss(n_classes=n_classes, source=False)\n",
    "            # Entropy minimization loss\n",
    "            self.tgt_entropy_loss = EntropyMinimizationLoss(n_classes=n_classes)   \n",
    "\n",
    "            \n",
    "    def train_step(self, X_source: Tensor, y_source: Tensor, X_target: Tensor):\n",
    "        \n",
    "        # Tell model go training mode\n",
    "        self.model.model.train()\n",
    "        \n",
    "        # Compute features for both inputs\n",
    "        X_source_features = self.model.model(X_source)\n",
    "        X_target_features = self.model.model(X_target)\n",
    "        \n",
    "        # Compute overall training objective losses\n",
    "        classifier_loss, generator_loss = self.overall_losses(X_source_features, X_target_features, y_source)\n",
    "\n",
    "        # Compute gradients w.r.t. classifier loss\n",
    "        self.model.optim.zero_grad()\n",
    "        classifier_loss.backward(retain_graph=True)\n",
    "        grad_classifier_tmp = []\n",
    "        for p in self.model.model.parameters():\n",
    "            if p.grad is not None:\n",
    "                grad_classifier_tmp.append(p.grad.data.clone())\n",
    "        \n",
    "            \n",
    "        # Compute gradients w.r.t. generator loss\n",
    "        self.model.optim.zero_grad()\n",
    "        generator_loss.backward()\n",
    "        grad_generator_tmp = []\n",
    "        for p in self.model.model.parameters():\n",
    "            if p.grad is not None:\n",
    "                grad_generator_tmp.append(p.grad.data.clone())\n",
    "    \n",
    "        count = 0 \n",
    "        appended = 0 \n",
    "        n_classification_params = 2 \n",
    "        n_params = len(list(self.model.model.parameters()))\n",
    "        for p in self.model.model.parameters():\n",
    "            if p.grad is not None:\n",
    "                grad_tmp = p.grad.data.clone()\n",
    "                grad_tmp.zero_() \n",
    "                \n",
    "                # Whereas the last 2 parameters are trained with classifier loss,\n",
    "                # the others are trained with the generator loss  \n",
    "                if count < (n_params - n_classification_params): \n",
    "                    grad_tmp = grad_tmp + grad_generator_tmp[appended]\n",
    "                else: \n",
    "                    grad_tmp = grad_tmp + grad_classifier_tmp[appended]\n",
    "                appended = appended + 1 \n",
    "                p.grad.data = grad_tmp\n",
    "            count = count + 1 \n",
    "        \n",
    "        # Perform optimizer step    \n",
    "        self.model.optim.step()\n",
    "    \n",
    "    def train_epoch(self, source_dataloader: DataLoader, target_dataloader: DataLoader):\n",
    "        end_of_epoch = False\n",
    "        source_batch_loader = enumerate(source_dataloader)\n",
    "        target_batch_loader = enumerate(target_dataloader)\n",
    "        \n",
    "        # Train for current epoch\n",
    "        while not end_of_epoch:\n",
    "            try:\n",
    "                # Get next batch for both source and target\n",
    "                (X_source, y_source) = source_batch_loader.__next__()[1]\n",
    "                (X_target, _) = target_batch_loader.__next__()[1]\n",
    "                self.train_step(X_source, y_source, X_target)\n",
    "            except StopIteration:\n",
    "                end_of_epoch = True\n",
    "                return\n",
    "            \n",
    "    def train(self, source_dataloader: DataLoader, target_dataloader: DataLoader):\n",
    "        while self.curr_epoch < self.tot_epochs:\n",
    "            self.curr_epoch = self.curr_epoch + 1\n",
    "            self.train_epoch(source_dataloader, target_dataloader)\n",
    "    \n",
    "   \n",
    "    def overall_losses(self, X_source_features, X_target_features, y_source_var) -> tuple[Tensor, Tensor]:\n",
    "        # Source task classifier loss\n",
    "        self.src_task_class_loss.y_labels = y_source_var\n",
    "        _src_task_class_loss = self.src_task_class_loss(X_source_features)\n",
    "        \n",
    "        # (Cross-domain) Target task classifier loss\n",
    "        self.tgt_task_class_loss.y_labels = y_source_var\n",
    "        _tgt_task_class_loss = self.tgt_task_class_loss(X_source_features)\n",
    "        \n",
    "        # Domain discrimination loss\n",
    "        _src_dom_discrim_loss = self.src_dom_discrim_loss(X_source_features)\n",
    "        _tgt_dom_discrim_loss = self.tgt_dom_discrim_loss(X_target_features)\n",
    "        _domain_discrim_loss = TrainingObjectives.domain_discrimination_loss(\n",
    "            _src_dom_discrim_loss, \n",
    "            _tgt_dom_discrim_loss\n",
    "        )\n",
    "        \n",
    "        # Category-level confusion loss\n",
    "        self.src_cat_conf_loss.y_labels = y_source_var\n",
    "        self.tgt_cat_conf_loss.y_labels = y_source_var\n",
    "        _src_cat_conf_loss = self.src_cat_conf_loss(X_source_features)\n",
    "        _tgt_cat_conf_loss = self.tgt_cat_conf_loss(X_source_features)\n",
    "        _category_conf_loss = TrainingObjectives.category_confusion_loss(\n",
    "            _src_cat_conf_loss, \n",
    "            _tgt_cat_conf_loss\n",
    "        )\n",
    "        \n",
    "        # Domain-level confusion loss\n",
    "        _src_dom_conf_loss = self.src_cat_conf_loss(X_target_features)\n",
    "        _tgt_dom_conf_loss = self.tgt_cat_conf_loss(X_target_features)\n",
    "        _domain_conf_loss = TrainingObjectives.domain_confusion_loss(\n",
    "            _src_dom_conf_loss, \n",
    "            _tgt_dom_conf_loss\n",
    "        )\n",
    "\n",
    "        # Entropy minimization loss\n",
    "        _tgt_entropy_loss = self.tgt_entropy_loss(X_target_features)\n",
    "        \n",
    "        # Overall classifier loss\n",
    "        _overall_classifier_loss = TrainingObjectives.overall_classifier_loss(\n",
    "            _src_task_class_loss, \n",
    "            _tgt_task_class_loss, \n",
    "            _domain_discrim_loss\n",
    "        )\n",
    "\n",
    "        # Overall feature extractor loss\n",
    "        _overall_generator_loss = TrainingObjectives.overall_generator_loss(\n",
    "            _category_conf_loss, \n",
    "            _domain_conf_loss, \n",
    "            _tgt_entropy_loss, \n",
    "            self.curr_epoch, \n",
    "            self.tot_epochs\n",
    "        )\n",
    "        \n",
    "        return _overall_classifier_loss, _overall_generator_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=0'>1</a>\u001b[0m generator \u001b[39m=\u001b[39m FeatureExtractor(n_classes\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mresnet50\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=1'>2</a>\u001b[0m symnet \u001b[39m=\u001b[39m ModelTrainer(model\u001b[39m=\u001b[39mgenerator, n_classes\u001b[39m=\u001b[39m\u001b[39m20\u001b[39m, epochs\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=2'>3</a>\u001b[0m symnet\u001b[39m.\u001b[39;49mtrain(source_train_loader, target_train_loader)\n",
      "\u001b[1;32m/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb Cell 21\u001b[0m in \u001b[0;36mModelTrainer.train\u001b[0;34m(self, source_dataloader, target_dataloader)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=117'>118</a>\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurr_epoch \u001b[39m<\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtot_epochs:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=118'>119</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurr_epoch \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurr_epoch \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=119'>120</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_epoch(source_dataloader, target_dataloader)\n",
      "\u001b[1;32m/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb Cell 21\u001b[0m in \u001b[0;36mModelTrainer.train_epoch\u001b[0;34m(self, source_dataloader, target_dataloader)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=109'>110</a>\u001b[0m     (X_source, y_source) \u001b[39m=\u001b[39m source_batch_loader\u001b[39m.\u001b[39m\u001b[39m__next__\u001b[39m()[\u001b[39m1\u001b[39m]\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=110'>111</a>\u001b[0m     (X_target, _) \u001b[39m=\u001b[39m target_batch_loader\u001b[39m.\u001b[39m\u001b[39m__next__\u001b[39m()[\u001b[39m1\u001b[39m]\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=111'>112</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_step(X_source, y_source, X_target)\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=112'>113</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=113'>114</a>\u001b[0m     end_of_epoch \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[1;32m/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb Cell 21\u001b[0m in \u001b[0;36mModelTrainer.train_step\u001b[0;34m(self, X_source, y_source, X_target)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=54'>55</a>\u001b[0m \u001b[39m# Compute features for both inputs\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=55'>56</a>\u001b[0m X_source_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mmodel(X_source)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=56'>57</a>\u001b[0m X_target_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mmodel(X_target)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=58'>59</a>\u001b[0m \u001b[39m# Compute overall training objective losses\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000020?line=59'>60</a>\u001b[0m classifier_loss, generator_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moverall_losses(X_source_features, X_target_features, y_source)\n",
      "File \u001b[0;32m~/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/torchvision/models/resnet.py:283\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 283\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_forward_impl(x)\n",
      "File \u001b[0;32m~/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/torchvision/models/resnet.py:273\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(x)\n\u001b[1;32m    272\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(x)\n\u001b[0;32m--> 273\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer3(x)\n\u001b[1;32m    274\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer4(x)\n\u001b[1;32m    276\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mavgpool(x)\n",
      "File \u001b[0;32m~/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    140\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 141\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    142\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/torchvision/models/resnet.py:148\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    145\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn1(out)\n\u001b[1;32m    146\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n\u001b[0;32m--> 148\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv2(out)\n\u001b[1;32m    149\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbn2(out)\n\u001b[1;32m    150\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1110\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1106\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1107\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1111\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1112\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:447\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 447\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/Desktop/deep-learning-proj/venv/lib/python3.9/site-packages/torch/nn/modules/conv.py:443\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    440\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    441\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    442\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 443\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    444\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "generator = FeatureExtractor(n_classes=20, model='resnet50')\n",
    "symnet = ModelTrainer(model=generator, n_classes=20, epochs=1)\n",
    "symnet.train(source_train_loader, target_train_loader)\n",
    "\n",
    "# Qualcosa non funziona, perchè runna all'infinito "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation step "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'FeatureExtractor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb Cell 23\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mModelValidator\u001b[39;00m: \n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=2'>3</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model: FeatureExtractor, n_classes: \u001b[39mint\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=3'>4</a>\u001b[0m         \u001b[39m\"\"\"Initialize the SymsNet model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=4'>5</a>\u001b[0m \u001b[39m        Args:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=5'>6</a>\u001b[0m \u001b[39m            model (FeatureExtractor): _description_\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=6'>7</a>\u001b[0m \u001b[39m            n_classes (int): _description_\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=7'>8</a>\u001b[0m \u001b[39m            epochs (int): _description_\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=8'>9</a>\u001b[0m \u001b[39m        \"\"\"\u001b[39;00m\n",
      "\u001b[1;32m/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb Cell 23\u001b[0m in \u001b[0;36mModelValidator\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mModelValidator\u001b[39;00m: \n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=2'>3</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, model: FeatureExtractor, n_classes: \u001b[39mint\u001b[39m):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=3'>4</a>\u001b[0m         \u001b[39m\"\"\"Initialize the SymsNet model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=4'>5</a>\u001b[0m \u001b[39m        Args:\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=5'>6</a>\u001b[0m \u001b[39m            model (FeatureExtractor): _description_\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=6'>7</a>\u001b[0m \u001b[39m            n_classes (int): _description_\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=7'>8</a>\u001b[0m \u001b[39m            epochs (int): _description_\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=8'>9</a>\u001b[0m \u001b[39m        \"\"\"\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luciahrovatin/Desktop/deep-learning-proj/symNets.ipynb#ch0000022?line=9'>10</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel \u001b[39m=\u001b[39m model \n",
      "\u001b[0;31mNameError\u001b[0m: name 'FeatureExtractor' is not defined"
     ]
    }
   ],
   "source": [
    "class ModelValidator: \n",
    "    \n",
    "    def __init__(self, model: FeatureExtractor, n_classes: int):\n",
    "        \"\"\"Initialize the SymsNet model\n",
    "        Args:\n",
    "            model (FeatureExtractor): _description_\n",
    "            n_classes (int): _description_\n",
    "            epochs (int): _description_\n",
    "        \"\"\"\n",
    "        self.model = model \n",
    "        self.n_classes = n_classes\n",
    "        self.val_loss_source = []\n",
    "        self.val_loss_target = []\n",
    "        \n",
    "    def validation_step(self, input, target):\n",
    "        with torch.no_grad():\n",
    "            result = self.model.model(input)\n",
    "        \n",
    "        loss_source = CrossEntropyLoss(result[:, :self.n_classes], target)\n",
    "        loss_target = CrossEntropyLoss(result[:, self.n_classes:], target)\n",
    "        \n",
    "        return loss_source, loss_target\n",
    "        \n",
    "    \n",
    "    def validation(self, val_loader: DataLoader):\n",
    "        # activate the evaluation mode\n",
    "        self.model.model.eval()\n",
    "        \n",
    "        validator = enumerate(val_loader)\n",
    "        \n",
    "        for i, (input, target, _) in validator: \n",
    "            if torch.cuda.is_available():\n",
    "                input, target = input.cuda(), target.cuda()\n",
    "            ls_source, ls_target = self.validation_step(input, target)\n",
    "            self.val_loss_source.append(ls_source)\n",
    "            self.val_loss_target.append(ls_target)\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "     \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6f0d290f0742685d306541f8dcebbe79a177e37269f78587a0fc5052fa8d446c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
