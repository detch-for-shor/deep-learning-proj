{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Preliminary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import models\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet (a.k.a. Feature Extractor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "\n",
    "model_urls = {\n",
    "    'resnet18': 'https://download.pytorch.org/models/resnet18-5c106cde.pth',\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth'\n",
    "}\n",
    "\n",
    "\n",
    "def conv3x3(in_planes, out_planes, stride=1):\n",
    "    \"3x3 convolution with padding\"\n",
    "    return torch.nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "\n",
    "\n",
    "class BasicBlock(torch.nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(planes)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.conv2 = conv3x3(planes, planes)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(planes)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class Bottleneck(torch.nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(planes)\n",
    "        self.conv2 = torch.nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
    "                               padding=1, bias=False)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(planes)\n",
    "        self.conv3 = torch.nn.Conv2d(planes, planes * 4, kernel_size=1, bias=False)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(planes * 4)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes=1000):\n",
    "        self.inplanes = 64\n",
    "        super(ResNet, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(64)\n",
    "        self.relu = torch.nn.ReLU(inplace=True)\n",
    "        self.maxpool = torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
    "        self.avgpool = torch.nn.AvgPool2d(7)\n",
    "        self.fc = torch.nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, torch.nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, torch.nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, bias=False),\n",
    "                torch.nn.BatchNorm2d(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes))\n",
    "\n",
    "        return torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet18(args, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-18 model.\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(BasicBlock, [2, 2, 2, 2], num_classes=args.num_classes)\n",
    "    if args.pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet18']))\n",
    "    # modify the structure of the model.\n",
    "    num_of_feature_map = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(num_of_feature_map, args.num_classes * 2)\n",
    "    # model.fc.weight.data.normal_(0.0, 0.02)\n",
    "    # model.fc.bias.data.normal_(0)\n",
    "    return model\n",
    "\n",
    "class TestArgs:\n",
    "    def __init__(self, pretrained, num_classes):\n",
    "        self.pretrained = pretrained\n",
    "        self.num_classes = num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def feature_extractor(model='resnet18', n_classes=1000):\n",
    "    if model == 'resnet18': \n",
    "        model = models.resnet18(pretrained=True) # resnet18(TestArgs(True, 1000))\n",
    "    elif model == 'resnet50': \n",
    "        model = models.resnet50(pretrained=True)\n",
    "    else:\n",
    "        raise ValueError('Unknown model')\n",
    "    num_of_feature_map = model.fc.in_features\n",
    "    model.fc = torch.nn.Linear(num_of_feature_map, n_classes * 2)\n",
    "    return model # torch.nn.Sequential(*list(model.children())[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the two feature extractors in txt files\n",
    "with open('docs/resnet18_symnets.txt', 'w') as f:\n",
    "    f.write(feature_extractor().__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "with open('docs/resnet18_online.txt', 'w') as f:\n",
    "    f.write(model.__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('docs/resnet18_ours.txt', 'w') as f:\n",
    "    f.write(feature_extractor().__str__())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a batch of source images\n",
    "from PIL import Image\n",
    "\n",
    "folder = \"data/Adaptiope/product_images\"\n",
    "source_imgs = [\n",
    "    Image.open(f\"{folder}/bookcase/bookcase_000.jpg\").convert('RGB'),\n",
    "    Image.open(f\"{folder}/flat iron/flat iron_000.jpg\").convert('RGB'),\n",
    "    Image.open(f\"{folder}/ice skates/ice skates_000.jpg\").convert('RGB'),\n",
    "]\n",
    "# for img in source_imgs:\n",
    "#     img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape = torch.Size([3, 3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# Ricreate the preprocessingf pipeline as reported in data_prep\n",
    "preprocess = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )])\n",
    "\n",
    "# Preprocess images\n",
    "source_tns = list(map(preprocess, source_imgs))\n",
    "\n",
    "# Show preprocessed images\n",
    "# to_pil_img = transforms.ToPILImage()\n",
    "# for tns in source_tns:\n",
    "#     to_pil_img(tns).show()\n",
    "    \n",
    "# Create batch of images\n",
    "source_tns = [torch.unsqueeze(tns, 0) for tns in source_tns]\n",
    "source_batch = torch.cat(source_tns, dim=0)\n",
    "print('Batch shape =', source_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2000])\n",
      "tensor([[-0.3483, -0.3169, -0.3339,  ...,  0.1621, -0.5910, -1.1216],\n",
      "        [ 0.5512,  0.2212,  0.0630,  ...,  0.0849, -0.2852, -0.2853],\n",
      "        [-0.0732, -0.7080,  0.5453,  ...,  0.3829, -1.1158, -1.1359]],\n",
      "       grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Extract features through ResNet\n",
    "resnet = feature_extractor(model='resnet18')\n",
    "# resnet.eval()\n",
    "\n",
    "# Get latent repr for each image in batch\n",
    "features = resnet(source_batch)\n",
    "print(features.shape)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.Size([3, 2000])\n",
    "tensor([[ 0.2031,  0.2776, -0.0273,  ...,  0.1005,  1.0534,  0.4215],\n",
    "        [ 0.4832,  0.0222, -0.1837,  ...,  0.8101,  1.5281,  0.6838],\n",
    "        [ 1.0008,  0.1067, -0.0567,  ...,  0.1076,  1.6767,  0.8851]],\n",
    "       grad_fn=<AddmmBackward0>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6818, grad_fn=<NegBackward0>)\n",
      "tensor(0.7046, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "n_classes = 1000\n",
    "\n",
    "def add_threshold(prob: Tensor):\n",
    "    _THRESHOLD = 1e-20\n",
    "    zeros = (prob == 0)\n",
    "    if torch.any(zeros): # any(any(x) for x in zeros): \n",
    "        thre_tensor = torch.zeros(zeros.shape)\n",
    "        thre_tensor[zeros] = _THRESHOLD\n",
    "        prob += thre_tensor\n",
    "    return prob\n",
    "      \n",
    "def to_softmax(features: Tensor, split=False, source=True):\n",
    "    prob = F.softmax(features, dim=1)\n",
    "    prob = prob if not split else split_softmax(prob, source)\n",
    "    return add_threshold(prob)\n",
    "\n",
    "def split_softmax(prob: Tensor, source=True):\n",
    "    return prob[:,:n_classes] if source else prob[:,n_classes:]\n",
    "\n",
    "def cross_entropy_loss(prob: Tensor):\n",
    "    return -(prob.sum(dim=1).log().mean())\n",
    "\n",
    "# SourceDomainClassifier\n",
    "print(cross_entropy_loss(to_softmax(features, split=True, source=True)))\n",
    "\n",
    "# TargetDomainClassifier\n",
    "print(cross_entropy_loss(to_softmax(features, split=True, source=False)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit (windows store)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "16cbb1df62e8e69441bdf7dce00d4866841818461557dbda546dabf5a55996e0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
